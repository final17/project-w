input {
  file {
    path => "/usr/share/logstash/load/*.csv"
    start_position => "beginning"
  }
}

filter {
  csv {
    columns => ["id", "created_at", "updated_at", "address", "close_time", "description", "image", "is_deleted", 
                "is_next_day", "last_order", "open_time", "phone_number", "reservation_table_count", "table_count", 
                "title", "turnover", "menu", "user_id", "deposit", "latitude", "longitude", "district_category"]
    separator => ","
    quote_char => '"'
  }

  mutate {
    convert => {
      "id" => "integer"
      "created_at" => "string"
      "updated_at" => "string"
      "address" => "string"
      "close_time" => "string"
      "description" => "string"
      "image" => "string"
      "is_deleted" => "boolean"
      "is_next_day" => "boolean"
      "last_order" => "string"
      "open_time" => "string"
      "phone_number" => "string"
      "reservation_table_count" => "integer"
      "table_count" => "integer"
      "title" => "string"
      "turnover" => "string"
      "menu" => "string"
      "user_id" => "integer"
      "deposit" => "integer"
      "latitude" => "float"
      "longitude" => "float"
      "district_category" => "string"
    }

    remove_field => ["@version", "@timestamp", "host", "path", "message", "log", "event", "created_at", "updated_at", "view"]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "stores"
    user => "logstash_internal"
    password => "${LOGSTASH_INTERNAL_PASSWORD}"
  }
  stdout { codec => rubydebug }
}
